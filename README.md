# crowded-pedestrian-detection
The research in pedestrian detection has made remarkable progress in recent years. 
However, robust pedestrian detection in crowded scenes remains a considerable challenge. 
Many methods resort to additional annotations (visible body or head) of a dataset or develop attention mechanisms to alleviate the difficulties posed by occlusions. 
However, these methods rarely use contextual information to strengthen the features extracted by a backbone network. 
The main aim of this paper is to extract more effective and discriminative features of pedestrians for robust pedestrian detection with heavy occlusions. 
To this end, we propose a global context-aware module to exploit contextual information for pedestrian detection. 
Fusing global context with the information derived from the visible part of occluded pedestrians enhances feature representations. 
The experimental results obtained on two challenging benchmarks, CrowdHuman and CityPersons, demonstrate the effectiveness and merits of the proposed method.
